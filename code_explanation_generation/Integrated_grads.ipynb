{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23870199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model                                                            \n",
    "import sys\n",
    "import timeit\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle   \n",
    "from CUI098_custom_layers import Time2Vec, PeriodicEmbed, GradAccumModel, GlobalAvgPooling1DMask\n",
    "from CUI098_custom_layers import GlobalMaxPooling1DMask,PositionalEmbedding, BilinearMHAttention, PositionalEmbedding\n",
    "from CUI020_seq_loader import EmbeddingSequence\n",
    "import CUI099_utils as utils\n",
    "from tensorflow.keras.utils import Sequence  # to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import quantile_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a198d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "proj_dir = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "sys.path.append(proj_dir)\n",
    "sys.path.insert(0, os.path.join(cwd, os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f1f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rtdl\n",
    "sys.modules['rtdl.rtdl'] = rtdl\n",
    "from rtdl.rtdl.data import piecewise_linear_encoding,compute_piecewise_linear_encoding, PiecewiseLinearEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae09070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"]=\"1\"\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for gpu_dev in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu_dev, True)\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b701a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    if data_path.split('.')[-1] in ['txt', 'csv']:\n",
    "        dat = pd.read_csv(data_path)\n",
    "    elif data_path.split('.')[-1] == 'pickle':\n",
    "        with open(data_path, 'rb') as f:\n",
    "            dat = pickle.load(f)\n",
    "    elif data_path.split('.')[-1] == 'pkl':\n",
    "        with open(data_path, 'rb') as f:\n",
    "            dat = pickle.load(f)\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d5e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_id = 'encounter_id'\n",
    "time_since = 'hours_since_admit'\n",
    "outcome = 'first_stage2_48hrs'\n",
    "model_type = 'ts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bced73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding mechanism\n",
    "\n",
    "class EmbeddingSequence(Sequence):\n",
    "    \"\"\"Generates data for Keras\n",
    "    A child class from Sequence requires two methods: __len__ and __getitem__\n",
    "    The method __getitem__ should return a complete batch\n",
    "    \"\"\"\n",
    "    def __init__(self, x_in, y_in, list_IDs, max_ts_len=None, max_cui_len=None, batch_size=1, shuffle=True):\n",
    "        \"\"\"Initialization\n",
    "        :param x_in: pandas dataframe with each row containing the predictor observations at a single timepoint \n",
    "            - timeseries data AND/OR processed CUIs\n",
    "        :param y_in: pandas dataframe with each row being an outcome at a specific timepoint\n",
    "        :param list_IDs: list of all 'label' ids to use in the generator (typically list of encounter/study ids)\n",
    "        :param max_ts_len: Max number of timesteps a batch can be padded to \n",
    "        :param max_cui_len: Max number of CUIs a batch can be padded to \n",
    "        :param batch_size: batch size at each iteration\n",
    "        :param shuffle: True to shuffle label indexes after every epoch\n",
    "        \"\"\"\n",
    "        self.x_in = x_in\n",
    "        self.y_in = y_in\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        self.on_epoch_end()\n",
    "        if max_ts_len is None:\n",
    "            self.max_ts_len = 0\n",
    "        else:\n",
    "            self.max_ts_len = max_ts_len\n",
    "        if max_cui_len is None:\n",
    "            self.max_cui_len = 0\n",
    "        else:\n",
    "            self.max_cui_len = max_cui_len\n",
    "        self.time_dim = 't2v'\n",
    "        self.outcome = outcome\n",
    "        self.study_id = study_id\n",
    "        self.time_var = time_since\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denote the number of batches per epoch\n",
    "        :return: number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\n",
    "        on_epoch_end is triggered once at the very beginning as well as at the end of each epoch\n",
    "        \"\"\"\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        # Generate data\n",
    "        batch_X = self.x_in.loc[self.x_in[self.study_id].isin(list_IDs_temp)]\n",
    "        batch_y = self.y_in.loc[self.y_in[self.study_id].isin(list_IDs_temp)]\n",
    "\n",
    "        batch_X['timestep'] = batch_X.groupby(self.study_id).cumcount()\n",
    "        time_cols = [self.time_var]\n",
    "        \n",
    "        X_output = []\n",
    "        if model_type in ['ts', 'combo']:\n",
    "            # ts input\n",
    "            batch_ts = batch_X.drop([*time_cols, 'cui'], axis=1, errors='ignore')\n",
    "            batch_ts = (batch_ts.set_index([self.study_id, 'timestep']).groupby(level=0).apply(\n",
    "                lambda x: list(x.values)[-self.max_ts_len:])).tolist()\n",
    "            batch_ts = pad_sequences(batch_ts, value = -1, padding='post', dtype='float32')\n",
    "            batch_ts = batch_ts.astype('float32')\n",
    "            X_output.append(batch_ts)\n",
    "        \n",
    "        batch_X_time = batch_X.set_index([self.study_id, 'timestep']\n",
    "                                             ).groupby(level=0)[self.time_var].apply(\n",
    "        lambda x: list(x)[-self.max_ts_len:])\n",
    "        batch_X_time = pad_sequences(batch_X_time, value = -1, padding='post', dtype='float32')\n",
    "        X_output.append(batch_X_time)\n",
    "\n",
    "        batch_y['timestep'] = batch_y.groupby(self.study_id).cumcount()\n",
    "        batch_y = batch_y.set_index([self.study_id, 'timestep']).groupby(level=0)[self.outcome].apply(\n",
    "            lambda x: list(x)[-self.max_ts_len:])\n",
    "        \n",
    "        batch_y = pad_sequences(batch_y, padding='post', value=-1, dtype='float32')\n",
    "        batch_y = np.expand_dims(batch_y, axis=-1)\n",
    "        batch_y = batch_y.astype('float32')\n",
    "        \n",
    "\n",
    "        return X_output, batch_y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\n",
    "        :returns X and y\n",
    "            X is a list of X inputs to the model containing a combination of \n",
    "            structured, CUI, and timestep data to be use as input to the model\n",
    "        \"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        X,y = self.__data_generation(list_IDs_temp)\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c92636",
   "metadata": {},
   "source": [
    "### Read in model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90040219",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../Data/Analytic/aki_data_20240411-1019'\n",
    "model_dir = './'\n",
    "model_path = 'copy20240628-0910_best_model.h5'\n",
    "c_obs_path = 'copy20240621-1215_model_objects.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model objects\n",
    "transformer = read_data('copy20240610-1226_data_transformer.pickle')\n",
    "custom_obs = read_data(os.path.join(model_dir, c_obs_path))\n",
    "model = load_model(os.path.join(model_dir, model_path), \n",
    "                      custom_objects=custom_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9174a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_dict = read_data('new_input2.pkl')\n",
    "combo_dat = combo_dict['wrapper_df']['combined_dat']\n",
    "all_test_encs = combo_dict['wrapper_df']['test_encs']\n",
    "all_test_dat = combo_dat.loc[combo_dat[study_id].isin(all_test_encs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5bc37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dat = all_test_dat\n",
    "all_cols = combo_dict['orig_dat_noise'].columns\n",
    "median_val = np.expand_dims(np.median(test_dat[:100], axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d95bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input with median values as baseline\n",
    "med_baseline_data = pd.DataFrame(median_val, columns=combo_dict['wrapper_df']['combined_dat'].columns)\n",
    "med_baseline_data[study_id] = 101\n",
    "med_baseline_data[time_since] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11211752",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vars = combo_dict['wrapper_df']['pred_vars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_dict_background = read_data('real_background.pkl')\n",
    "dat_background = combo_dict_background['wrapper_df']['combined_dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b01af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of transformed columns from features\n",
    "col_sort = dat_background[combo_dict['wrapper_df']['pred_vars']].nunique()\n",
    "col_sort = pd.DataFrame(col_sort, columns =['count'])\n",
    "col_sort.loc[col_sort['count']>10, 'count']=10\n",
    "col_sort_dict = col_sort.to_dict()['count']\n",
    "col_list = []\n",
    "col_index_list = []\n",
    "for col in dat_background[combo_dict['wrapper_df']['pred_vars']].columns:\n",
    "    col_list.extend([col] * col_sort_dict[col])\n",
    "    col_index_list.extend(list(range(col_sort_dict[col])))\n",
    "    \n",
    "col_list2 = []\n",
    "for i in range(len(col_list)):\n",
    "    col_list2.append(f\"{col_list[i]}_{col_index_list[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing all data\n",
    "test_dat = all_test_dat\n",
    "test_encs = all_test_encs\n",
    "\n",
    "#defining some default values\n",
    "outcome = 'outcome_ward24hr'\n",
    "cuis = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrated_gradients(model, baseline, original, y, num_steps=50):\n",
    "    \n",
    "    # create inputs that incrementally change from baseline to original input\n",
    "    interpolated_inputs = []\n",
    "    for i in range(len(original)):\n",
    "        interpolated_inputs.append(tf.linspace(baseline[i], original[i], num_steps+1)[1:])\n",
    "    \n",
    "    # run each new input through the model to obtain gradients\n",
    "    gradients = []\n",
    "    for s in range(num_steps):\n",
    "        trans_dat = pd.DataFrame(transformer.transform(np.array(interpolated_inputs[0][s])))\n",
    "        trans_dat[study_id] =  list(y_test[study_id])[0]\n",
    "        trans_dat[time_since] = interpolated_inputs[1][s]\n",
    "        test_generator = EmbeddingSequence(trans_dat, y, [list(y_test[study_id])[0]], max_cui_len=2000, \n",
    "                                           max_ts_len=2000, batch_size=1, shuffle=False)\n",
    "        inputs, extra = test_generator.__getitem__(0)\n",
    "        n_time = original[0].shape[0]\n",
    "        inputs_tf = [tf.convert_to_tensor(inputs[0]), tf.ones(shape=(1,n_time,1)),tf.convert_to_tensor(inputs[1])]\n",
    "        with tf.GradientTape() as tape:\n",
    "            #fix to have variable number of inputs\n",
    "            tape.watch(inputs_tf)\n",
    "            output = model(inputs_tf)\n",
    "            \n",
    "        grad = tape.gradient(output, inputs_tf)\n",
    "        gradients.append(grad)\n",
    "    gradients = [[y for y in x if y is not None] for x in gradients]\n",
    "    \n",
    "    avg_gradients = [tf.reduce_mean(g, axis=0) for g in zip(*gradients)]\n",
    "    \n",
    "    return avg_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60367464",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_baseline_data2 = pd.DataFrame(\n",
    "    np.repeat(med_baseline_data, 200, axis=0).astype(np.float32), \n",
    "    columns=all_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200bcaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start=timeit.default_timer()\n",
    "\n",
    "num_steps = 5000\n",
    "int_grad_dfs = []\n",
    "feature_int_grads = []\n",
    "int_grads_ts = []\n",
    "\n",
    "for n in range(len(test_encs)):\n",
    "    test_n = test_dat.loc[test_dat[study_id] == test_encs[n]]\n",
    "    y_test = test_n[[study_id, time_since, outcome]]\n",
    "    X_test_n = tf.convert_to_tensor(test_n[pred_vars])\n",
    "    test_n_time = tf.convert_to_tensor(test_n[time_since], dtype=float)\n",
    "    \n",
    "    baseline = tf.convert_to_tensor(med_baseline_data2[pred_vars].iloc[:X_test_n.shape[0], :])\n",
    "    baseline_time = tf.convert_to_tensor(0, dtype=float)\n",
    "    \n",
    "    avg_gradients = integrated_gradients(model, \n",
    "                                         [baseline, baseline_time, cuis], \n",
    "                                         [X_test_n,test_n_time,cuis], \n",
    "                                         y_test, \n",
    "                                         num_steps=num_steps)\n",
    "    \n",
    "    # get differences between original and baseline after transformation\n",
    "    orig_transformed = transformer.transform(np.array(X_test_n))\n",
    "    base_transformed = transformer.transform(np.array(baseline))\n",
    "    trans_diffs = [orig_transformed-base_transformed]\n",
    "    # time baseline is 0, so the difference is equal to the original values\n",
    "    trans_diffs.append(test_n_time)\n",
    "    \n",
    "    int_grads = {}\n",
    "    for i in range(len(trans_diffs)):\n",
    "        int_grads[i] = tf.convert_to_tensor([trans_diffs[i]], 'float32') * avg_gradients[i]\n",
    "        \n",
    "    int_grad_df = pd.DataFrame(int_grads[0][0].numpy(), columns = col_list2)\n",
    "    int_grad_dfs.append(int_grad_df)\n",
    "    feature_igs = int_grad_df.T.reset_index(names='feature')\n",
    "    feature_igs['feature'] = feature_igs['feature'].apply(lambda x: str(x)[0:-2])\n",
    "    feature_igs = feature_igs.groupby('feature').sum().T.reset_index(drop=True)\n",
    "    \n",
    "    feature_int_grads.append(feature_igs)\n",
    "    int_grad_ts = pd.DataFrame(int_grads[1][0].numpy(), columns =['time_grad'])\n",
    "    int_grads_ts.append(int_grad_ts)\n",
    "\n",
    "#show time taken\n",
    "print(np.round((timeit.default_timer()-time_start)/60, 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feat_grads = pd.concat(feature_int_grads, axis=0)\n",
    "all_feat_grads[pred_vars].abs().mean().sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a96dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the explanations\n",
    "IG_importances = []\n",
    "\n",
    "for case_num, enc_id in enumerate(combo_dict['wrapper_df']['combined_dat']['encounter_id'].unique()):\n",
    "    print(f\"case_num: {case_num}\")\n",
    "    original_data = combo_dict['wrapper_df']['combined_dat'][combo_dict['wrapper_df']['combined_dat']['encounter_id'] == enc_id]\n",
    "    print(f\"original_data: {original_data.shape}\")\n",
    "    \n",
    "    importance_holder = pd.DataFrame(np.zeros_like(original_data), columns=combo_dict['wrapper_df']['combined_dat'].columns)\n",
    "    importance_vals = feature_int_grads[case_num]\n",
    "    \n",
    "    for col_v in importance_vals.columns:\n",
    "        importance_holder[col_v] = importance_vals[col_v]\n",
    "        \n",
    "    IG_importances.append({\n",
    "        'case': case_num,\n",
    "        'original': original_data,\n",
    "        'importance': importance_holder,\n",
    "    }) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b780b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the explanations\n",
    "pickle.dump(IG_importances, open('trial22_vis_outs/IntegratedGradients', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369ecf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
